## 面试遇到的算法问题
1. **在 N 个数中，找到前 k 个数** 或者 **100亿个数字找出最大的10个**
> 链接1：https://www.zhihu.com/question/28874340/answer/43276792
链接2：https://my.oschina.net/letiantian/blog/333091
链接3：http://www.cnblogs.com/nzbbody/p/3576894.html

>     
    1亿 = 100M 相对于现在的硬件来说是个很小的数，基本上可以都 fit 进内存。内存中找前 k 个数可以用 Quickselect 算法，一个类似 quicksort 的算法，平均复杂度是 O(N)。
> 
如果总数据量更多，或者可用内存更小，可以把所有的数分成内存可以放下的多个部分，每个部分分别找前 k 个，最后把所有的数放在一起再找一次前 k，如果还放不下继续分堆。这个策略还可以让算法可以并行执行，有计算资源的时候降低整体执行时间。
> 
这个算法比建一个大小为 k 的最大堆要快，因为后者最后得到的 k 个数是部分有序的，复杂度会变成 O(N log k)，而前者得到的前 k 个数是完全无序的。

或者
> 1. 
**算法如下**：根据快速排序划分的思想 
(1) 递归对所有数据分成[a,b）b（b,d]两个区间，(b,d]区间内的数都是大于[a,b)区间内的数 
(2) 对(b,d]重复(1)操作，直到最右边的区间个数小于100个。注意[a,b)区间不用划分 
(3) 返回上一个区间，并返回此区间的数字数目。接着方法仍然是对上一区间的左边进行划分，分为[a2,b2）b2（b2,d2]两个区间，取（b2,d2]区间。如果个数不够，继续(3)操作，如果个数超过100的就重复1操作，直到最后右边只有100个数为止。 

> 
2.先取出前100个数，维护一个100个数的最小堆，遍历一遍剩余的元素，在此过程中维护堆就可以了。具体步骤如下： 
**step1**：取前m个元素（例如m=100），建立一个小顶堆。保持一个小顶堆得性质的步骤，运行时间为O（lgm);建立一个小顶堆运行时间为m*O（lgm）=O(m lgm);       
**step2**:顺序读取后续元素，直到结束。每次读取一个元素，如果该元素比堆顶元素小，直接丢弃 
如果大于堆顶元素，则用该元素替换堆顶元素，然后保持最小堆性质。最坏情况是每次都需要替换掉堆顶的最小元素，因此需要维护堆的代价为(N-m)*O(lgm); 
最后这个堆中的元素就是前最大的10W个。时间复杂度为O(N lgm）。 
>
**补充：**这个方法的说法也可以更简化一些：
假设数组arr保存100个数字，首先取前100个数字放入数组arr，对于第101个数字k，如果k大于arr中的最小数，则用k替换最小数，对剩下的数字都进行这种处理。
>
**3.分块查找** 
先把100w个数分成100份，每份1w个数。先分别找出每1w个数里面的最大的数，然后比较。找出100个最大的数中的最大的数和最小的数，取最大数的这组的第二大的数，与最小的数比较。。。。

或者
> 1、首先一点，对于海量数据处理，思路基本上是确定的，必须分块处理，然后再合并起来。
>
2、对于每一块必须找出10个最大的数，因为第一块中10个最大数中的最小的，可能比第二块中10最大数中的最大的还要大。
>
3、分块处理，再合并。也就是Google MapReduce 的基本思想。Google有很多的服务器，每个服务器又有很多的CPU，因此，100亿个数分成100块，每个服务器处理一块，1亿个数分成100块，每个CPU处理一块。然后再从下往上合并。注意：分块的时候，要保证块与块之间独立，没有依赖关系，否则不能完全并行处理，线程之间要互斥。另外一点，分块处理过程中，不要有副作用，也就是不要修改原数据，否则下次计算结果就不一样了。
>
4、上面讲了，对于海量数据，使用多个服务器，多个CPU可以并行，显著提高效率。对于单个服务器，单个CPU有没有意义呢？
>
　　也有很大的意义。如果不分块，相当于对100亿个数字遍历，作比较。这中间存在大量的没有必要的比较。可以举个例子说明，全校高一有100个班，我想找出全校前10名的同学，很傻的办法就是，把高一100个班的同学成绩都取出来，作比较，这个比较数据量太大了。应该很容易想到，班里的第11名，不可能是全校的前10名。也就是说，不是班里的前10名，就不可能是全校的前10名。因此，只需要把每个班里的前10取出来，作比较就行了，这样比较的数据量就大大地减少了。